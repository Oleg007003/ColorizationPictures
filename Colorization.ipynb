{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8kr3lIW2ulFSqw8HFy3Bl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oleg007003/ColorizationPictures/blob/main/Colorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqc1tkYfhPsT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y7FRh777BBa"
      },
      "source": [
        "!wget http://sereja.me/f/universum_compressed.tar\n",
        "!tar xf universum_compressed.tar\n",
        "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "!tar xf lfw.tgz\n",
        "\n",
        "!mv lfw/* universum-photos/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PdPE0AD7HzE"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d olgabelitskaya/flower-color-images\n",
        "!unzip flower-color-images.zip -d '/content/colors/'\n",
        "!mv colors/* universum-photos/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDdrWfqG7QpJ"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, path, transform_x, transform_y):\n",
        "        self.transform_x = transform_x\n",
        "        self.transform_y = transform_y\n",
        "      \n",
        "        filenames = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for file in files:\n",
        "                if file.endswith('.jpg') or file.endswith('.JPG'):\n",
        "                    filenames.append(os.path.join(root, file))\n",
        "\n",
        "        self.images = []\n",
        "        for filename in tqdm(filenames):\n",
        "            try:\n",
        "                with Image.open(filename) as image:\n",
        "                    self.images.append(image.copy())\n",
        "            except:\n",
        "                pass\n",
        "                #print('Could not load image:', filename)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        Y = self.transform_y(img)\n",
        "        X = self.transform_x(Y)\n",
        "        return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osjj6mWO7R93"
      },
      "source": [
        "transform_all = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomRotation(degrees=(-45, 45)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def to_grayscale(x):\n",
        "    return (x[0] * 0.299 + x[1] * 0.587 + x[2] * 0.114).view(1, 128, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbTroEGO7TkC"
      },
      "source": [
        "dataset = ColorizationDataset('universum-photos/', to_grayscale, transform_all)\n",
        "loader = DataLoader(dataset, batch_size=50, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBNPIi6N7sxz"
      },
      "source": [
        "class Colorizer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.preconcat = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, (3, 3), padding=1), \n",
        "            nn.BatchNorm2d(8),\n",
        "            #nn.MaxPool2d((2,2), stride=(2,2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 8, (3,3), padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            #nn.MaxPool2d((2,2), stride=(2,2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8,32, (3,3), padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, (3, 3), padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, (3, 3), padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(128, 256, (3, 3), padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, (3, 3), padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),   \n",
        "            nn.Conv2d(128, 64, (3, 3), padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),    \n",
        "            nn.Conv2d(64, 64, (3, 3), padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "         \n",
        "        self.postconcat = nn.Sequential(\n",
        "            nn.Conv2d(65, 32, (3, 3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 8, (3, 3), padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Conv2d(8, 8, (3, 3), padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(8, 3, (3, 3), padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.preconcat(x)\n",
        "        h = torch.cat((h, x), 1)\n",
        "        h = self.postconcat(h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk3bB5ir72Ko"
      },
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    torch.nn.init.normal(m.weight, 0.0, 0.02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "    torch.nn.init.zeros_(m.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLoFj5AW76ju"
      },
      "source": [
        "num_epochs = 14\n",
        "lr = 5e-3\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Colorizer().to(device)\n",
        "model.apply(weights_init)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "criterion = nn.SmoothL1Loss()  # тут можно поиграться с лоссами\n",
        "criterion2 = nn.MSELoss()  \n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_wQMJfA8XB9"
      },
      "source": [
        "history = []\n",
        "i = 0\n",
        "#losses = utils.AverageMeter()\n",
        "for epoch in range(num_epochs):\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion2(output, y)\n",
        "        loss.backward() \n",
        "        oX = x[0]\n",
        "        oY = y[0]\n",
        "        oR = output[0]\n",
        "        history.append(loss.item())\n",
        "        optimizer.step()\n",
        "      #  losses.update(loss.cpu().item(), x.size(0))\n",
        "        del x\n",
        "        del y\n",
        "        del output\n",
        "        torch.cuda.empty_cache()\n",
        "        # теперь сами:\n",
        "        # 0. распакавать данные на нужное устройство+\n",
        "        # 1. сбросить градиент+\n",
        "        # 2. прогнать данные через сеть+\n",
        "        # 3. посчитать loss+\n",
        "        # 4. залоггировать его куда-нибудь+\n",
        "        # 5. сделать .backward()+\n",
        "        # 6. optimizer.step()+\n",
        "        # (7. вывести пример колоризации -- см код ниже)\n",
        "        #print(loss.item())\n",
        "    print(i)\n",
        "    i += 1\n",
        "model.eval()\n",
        "tm = model(predicting)[0].detach().cpu()\n",
        "model.train()\n",
        "npimg = tm.numpy()\n",
        "npimg = np.clip(npimg, 0.,1)\n",
        "mping_color = np.transpose(npimg,(1,2,0))\n",
        "#Image.fromarray((npimg_color*255).astype(np.uint8)).save(f\"gif/{epoch}.png\")\n",
        "show_img((oX.detach().cpu(), oY.detach().cpu(), oR.detach().cpu()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92BSArZu8iI0"
      },
      "source": [
        "def show_img(sample):\n",
        "  img = sample[1]\n",
        "  img = img / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  npimg = np.clip(npimg, 0., 1.)\n",
        "  npimg_color = np.transpose(npimg, (1, 2, 0))\n",
        "  X = sample[0]\n",
        "  _, H, W = X.shape\n",
        "  img = np.zeros((H, W, 3))\n",
        "  img[:,:,1] = img[:,:,2] = img[:,:,0] = X\n",
        "  f = plt.figure(figsize=(20,20))\n",
        "  f.add_subplot(1,3,1)\n",
        "  plt.imshow(img)\n",
        "  f.add_subplot(1,3,2)\n",
        "  plt.imshow(npimg_color)\n",
        "  if len(sample) > 2:\n",
        "    rest = sample[2]\n",
        "    npimg = rest.numpy()\n",
        "    npimg = np.clip(npimg, 0., 1.)\n",
        "    npimg_color = np.transpose(npimg, (1,2,0))\n",
        "    f.add_subplot(1,3,3)\n",
        "    plt.imshow(npimg_color)\n",
        "  plt.show(block=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22rdj6L78mPl"
      },
      "source": [
        "def to_numpy_image(img):\n",
        "    return img.detach().cpu().view(3, 128, 128).transpose(0, 1).transpose(1, 2).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arfS3RUt8n5C"
      },
      "source": [
        "for t in range(10):\n",
        "    img_gray, img_true = dataset[t]\n",
        "    img_pred = model(img_gray.to(device).view(1, 1, 128, 128))\n",
        "    img_pred = to_numpy_image(img_pred)\n",
        "    # теперь это numpy-евский ndarray размера (128, 128, 3)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    \n",
        "    plt.subplot(141)\n",
        "    plt.axis('off')\n",
        "    plt.set_cmap('Greys')\n",
        "    plt.imshow(img_gray.reshape((128, 128)))\n",
        "\n",
        "    plt.subplot(142)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img_pred.reshape((128, 128, 3)))\n",
        "\n",
        "    plt.subplot(143)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(to_numpy_image(img_true))\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}